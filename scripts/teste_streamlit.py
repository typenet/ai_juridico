import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Define o modelo
model = genai.GenerativeModel("models/gemini-1.5-pro")  # ou outro da sua lista

st.title("üß† Teste de Prompts com Gemini")
st.markdown("Use este app para testar respostas do modelo Gemini com diferentes estilos de prompts.")

# Entrada do texto base
texto_base = st.text_area("Texto base para o modelo interpretar", "O contrato estipula que o cliente tem 7 dias para desist√™ncia.")

# Tipo de prompt
tipo_prompt = st.selectbox(
    "Selecione o estilo de resposta desejado:",
    ["Resumo jur√≠dico", "Resumo simples", "Explica√ß√£o jur√≠dica", "T√≥picos resumidos", "Reescrever em linguagem simples"]
)

# Gera√ß√£o de prompt
def montar_prompt(texto, tipo):
    if tipo == "Resumo jur√≠dico":
        return f"Resuma formalmente o seguinte conte√∫do jur√≠dico com linguagem t√©cnica clara:\n\n{texto}"
    elif tipo == "Resumo simples":
        return f"Fa√ßa um resumo claro e simples do seguinte texto:\n\n{texto}"
    elif tipo == "Explica√ß√£o jur√≠dica":
        return f"Explique o significado jur√≠dico do seguinte trecho:\n\n{texto}"
    elif tipo == "T√≥picos resumidos":
        return f"Liste em t√≥picos os principais pontos do seguinte texto jur√≠dico:\n\n{texto}"
    elif tipo == "Reescrever em linguagem simples":
        return f"Reescreva o seguinte texto jur√≠dico em uma linguagem acess√≠vel para leigos:\n\n{texto}"
    else:
        return texto

# Bot√£o de execu√ß√£o
if st.button("Gerar resposta"):
    with st.spinner("Consultando o modelo Gemini..."):
        try:
            prompt = montar_prompt(texto_base, tipo_prompt)
            response = model.generate_content(prompt)
            st.success("‚úÖ Resposta gerada com sucesso:")
            st.markdown(response.text)
        except Exception as e:
            st.error(f"‚ùå Erro ao gerar conte√∫do: {e}")
